{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fcntl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# utils_vlm_move.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Process input command, use multimodal large model for image recognition, control robotic gripper to pick and move objects\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print('Luo Research Lab')\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_robot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_asr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_vlm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32me:\\py11.11\\utils_robot.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msmbus2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmbus\u001b[39;00m   \u001b[38;5;66;03m#import smbus 树莓派自己修改回来\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\smbus2\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"smbus2 - A drop-in replacement for smbus-cffi/smbus-python\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# The MIT License (MIT)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2020 Karl-Petter Lindegaard\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# SOFTWARE.\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmbus2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMBus, i2c_msg, I2cFunc  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     25\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.5.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMBus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi2c_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI2cFunc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\smbus2\\smbus2.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfcntl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ioctl\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m c_uint32, c_uint8, c_uint16, c_char, POINTER, Structure, Array, Union, create_string_buffer, string_at\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Commands from uapi/linux/i2c-dev.h\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fcntl'"
     ]
    }
   ],
   "source": [
    "# utils_vlm_move.py\n",
    "# Process input command, use multimodal large model for image recognition, control robotic gripper to pick and move objects\n",
    "\n",
    "# print('Luo Research Lab')\n",
    "\n",
    "from utils_robot import *\n",
    "from utils_asr import *\n",
    "from utils_vlm import *\n",
    "\n",
    "import time\n",
    "\n",
    "def vlm_move(PROMPT='Please place the green block on the hand', input_way='keyboard'):\n",
    "    '''\n",
    "    Use multimodal large model for image recognition, control the gripper to pick and move objects\n",
    "    input_way: 'speech' for speech input, 'keyboard' for keyboard input\n",
    "    '''\n",
    "\n",
    "    print('Using multimodal large model for image recognition, controlling gripper to pick and move objects')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Resetting the robotic arm')\n",
    "    pwm_values = [1500, 1500, 1500, 1500, 1610, 1500]  # Specified PWM pulse widths\n",
    "\n",
    "    for i, pwm in enumerate(pwm_values):\n",
    "        pca.setServoPulse(i, pwm)  # Set PWM pulse width for the corresponding channel\n",
    "        print(f'Setting PWM pulse width for channel {i} to {pwm}')\n",
    "\n",
    "    time.sleep(3)  # Pause for 3 seconds to ensure the robotic arm completes the action\n",
    "\n",
    "    ## Step 1: Complete hand-eye calibration\n",
    "    print('Step 1: Complete hand-eye calibration')\n",
    "\n",
    "    ## Step 2: Issue the command\n",
    "    # PROMPT_BACKUP = 'Please place the green block on the hand' # Default command\n",
    "    \n",
    "    # if input_way == 'keyboard':\n",
    "    #     PROMPT = input('Step 2: Enter command')\n",
    "    #     if PROMPT == '':\n",
    "    #         PROMPT = PROMPT_BACKUP\n",
    "    # elif input_way == 'speech':\n",
    "    #     record()  # Start recording\n",
    "    #     PROMPT = speech_recognition()  # Speech recognition\n",
    "    print('Step 2, the issued command is:', PROMPT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Step 3: Capture top-view image\n",
    "    print('Step 3: Capture top-view image')\n",
    "    top_view_shot(check=False)\n",
    "\n",
    "    ## Step 4: Input the image to the multimodal vision model\n",
    "    print('Step 4: Input the image to the multimodal vision model')\n",
    "    img_path = 'temp/vl_now.jpg'\n",
    "\n",
    "    n = 1\n",
    "    while n < 5:\n",
    "        try:\n",
    "            print(f'    Attempting to access the multimodal model, attempt {n}')\n",
    "            result = yi_vision_api(PROMPT, img_path='temp/vl_now.jpg')\n",
    "            print('    Multimodal model call successful!')\n",
    "            print(result)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print('    Error in data structure returned by the multimodal model, retrying', e)\n",
    "            n += 1\n",
    "\n",
    "    ## Step 5: Post-processing and visualization of the model output\n",
    "    print('Step 5: Post-processing and visualization of the model output')\n",
    "    START_X_CENTER, START_Y_CENTER, END_X_CENTER, END_Y_CENTER = post_processing_viz(result, img_path, check=True)\n",
    "\n",
    "    ## Step 6: Convert pixel coordinates to robotic arm coordinates\n",
    "    print('Step 6: Hand-eye calibration, converting pixel coordinates to robotic arm coordinates')\n",
    "    # Start point in robotic arm coordinates\n",
    "    START_X_MC, START_Y_MC = eye2hand(START_X_CENTER, START_Y_CENTER)\n",
    "    # End point in robotic arm coordinates\n",
    "    END_X_MC, END_Y_MC = eye2hand(END_X_CENTER, END_Y_CENTER)\n",
    "\n",
    "    ## Step 7: Use the gripper pump to pick and move the object\n",
    "    print('Step 7: Using the gripper to pick and move the object')\n",
    "    pump_move(mc=mc, XY_START=[START_X_MC, START_Y_MC], XY_END=[END_X_MC, END_Y_MC])\n",
    "\n",
    "    ## Step 8: Cleanup\n",
    "    print('Step 8: Task completed')\n",
    "    GPIO.cleanup()            # Release GPIO pin channel\n",
    "    cv2.destroyAllWindows()   # Close all OpenCV windows\n",
    "    # exit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
